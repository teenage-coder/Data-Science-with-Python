{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet Sentiment Analysis - ANN",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuDeQL_mOHZr"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8NO-B0fv3PI",
        "outputId": "8d533eab-4d20-44b9-a8ff-067ca3dc1771"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk import word_tokenize\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 302
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5taxcueazuWJ"
      },
      "source": [
        "df = pd.read_csv('Tweets.csv')\n",
        "\n",
        "tweets = df['text']\n",
        "sentm = df['airline_sentiment']"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbV9jxEDz2GD"
      },
      "source": [
        "corpus = ''\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "\n",
        "  clean_txt = tweets[i].lower()                # Lowercase\n",
        "\n",
        "  clean_txt = re.sub(r'\\W', \" \", clean_txt)    # Remove Special Character\n",
        "  clean_txt = re.sub(r'\\d', \"\", clean_txt)    # Remove Numbers\n",
        "\n",
        "  corpus = corpus + clean_txt"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VQXQ7onz6Hy"
      },
      "source": [
        "unique_words = list(set(word_tokenize(corpus)))"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qVdW4T-CwyQ"
      },
      "source": [
        "# Encoding and Decoding Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3lgG6YT9Y8d"
      },
      "source": [
        "word2int = {}\n",
        "\n",
        "for n,w in enumerate(unique_words):\n",
        "  word2int[w] = n\n",
        "\n",
        "int2word = dict(enumerate(unique_words))"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGh5EmrN-NN4"
      },
      "source": [
        "lbls = []\n",
        "\n",
        "for i in range(len(sentm)):\n",
        "  if(sentm[i] == 'negative'):\n",
        "    lbls.append(0)\n",
        "  else:\n",
        "    lbls.append(1)"
      ],
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlGmFmCDAx4h"
      },
      "source": [
        "encoded_tweets = []\n",
        "encoded_lbls = []\n",
        "\n",
        "c = 0\n",
        "\n",
        "for i in range(len(tweets)):\n",
        "  \n",
        "  try:\n",
        "    tweet = tweets[i].lower()\n",
        "    tweet = re.sub(r'\\W', \" \", tweet)\n",
        "    tweet = re.sub(r'\\d', \"\", tweet)\n",
        "    \n",
        "    tweet = word_tokenize(tweet)\n",
        "\n",
        "    encoded = []\n",
        "    for j in tweet:\n",
        "      encoded.append(word2int[j])\n",
        "    \n",
        "    encoded_tweets.append(encoded)\n",
        "    encoded_lbls.append(lbls[i])\n",
        "\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 282,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrr4-pZIDpOe",
        "outputId": "5daab005-9e10-4818-8104-499d3ca7936f"
      },
      "source": [
        "encoded_tweets = np.array(encoded_tweets)\n",
        "encoded_lbls = np.array(encoded_lbls)"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggB6W321EbY2",
        "outputId": "71fae9ed-101d-44d6-c457-b355b0a5c3c3"
      },
      "source": [
        "for i in range(10):\n",
        "  print(len(encoded_tweets[i]),encoded_tweets[i])"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 [12722, 1121, 1780, 981]\n",
            "10 [12722, 12874, 2324, 11769, 8154, 10651, 5225, 2911, 3582, 1730]\n",
            "13 [12722, 5019, 11452, 6, 12828, 10333, 2885, 5019, 10057, 5225, 1960, 11929, 2154]\n",
            "18 [12722, 11115, 13008, 2482, 6354, 5225, 11142, 10736, 64, 13177, 10270, 4118, 12060, 6353, 4063, 6538, 2759, 13169]\n",
            "11 [12722, 10713, 11115, 13008, 5753, 2482, 4618, 11900, 13183, 4829, 11115]\n",
            "24 [12722, 11659, 5185, 11062, 5753, 3583, 7755, 9093, 12557, 11452, 6, 6538, 12624, 4635, 11115, 13008, 2482, 2911, 598, 11900, 13183, 4829, 5883, 9484]\n",
            "15 [12722, 7934, 9103, 5810, 6476, 5019, 3597, 4490, 12624, 12483, 3535, 6620, 6, 6086, 13012]\n",
            "16 [12722, 2482, 1641, 5753, 8808, 8825, 7755, 6531, 8454, 11922, 4803, 8162, 2307, 6, 10762, 6293]\n",
            "10 [12722, 11376, 5019, 11452, 6, 3796, 2999, 5019, 1508, 135]\n",
            "15 [12722, 11115, 217, 7287, 10713, 8033, 4229, 3370, 10235, 2324, 8502, 8430, 3558, 5225, 9618]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EL4LNjrEmzO"
      },
      "source": [
        "encoded_tweets = pad_sequences(encoded_tweets , 20)\n",
        "encoded_tweets = encoded_tweets / float(len(word2int))"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D69WWcR0KuUw"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, activation = 'relu', input_dim = (20)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02TYEUfEKv89",
        "outputId": "b84e495f-f6db-4328-dfc5-a10500b3835e"
      },
      "source": [
        "model.fit(encoded_tweets, encoded_lbls, epochs = 20, validation_split = .2)"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "365/365 [==============================] - 2s 2ms/step - loss: 0.6456 - accuracy: 0.6305 - val_loss: 0.5592 - val_accuracy: 0.7473\n",
            "Epoch 2/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6217 - accuracy: 0.6746 - val_loss: 0.5489 - val_accuracy: 0.7527\n",
            "Epoch 3/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6164 - accuracy: 0.6807 - val_loss: 0.5475 - val_accuracy: 0.7534\n",
            "Epoch 4/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6083 - accuracy: 0.6865 - val_loss: 0.5453 - val_accuracy: 0.7538\n",
            "Epoch 5/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6150 - accuracy: 0.6746 - val_loss: 0.5415 - val_accuracy: 0.7527\n",
            "Epoch 6/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6085 - accuracy: 0.6866 - val_loss: 0.5548 - val_accuracy: 0.7479\n",
            "Epoch 7/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6148 - accuracy: 0.6805 - val_loss: 0.5393 - val_accuracy: 0.7531\n",
            "Epoch 8/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6087 - accuracy: 0.6899 - val_loss: 0.5430 - val_accuracy: 0.7497\n",
            "Epoch 9/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6060 - accuracy: 0.6870 - val_loss: 0.5448 - val_accuracy: 0.7469\n",
            "Epoch 10/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6152 - accuracy: 0.6758 - val_loss: 0.5525 - val_accuracy: 0.7459\n",
            "Epoch 11/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6081 - accuracy: 0.6838 - val_loss: 0.5458 - val_accuracy: 0.7541\n",
            "Epoch 12/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6090 - accuracy: 0.6831 - val_loss: 0.5462 - val_accuracy: 0.7503\n",
            "Epoch 13/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.6906 - val_loss: 0.5450 - val_accuracy: 0.7510\n",
            "Epoch 14/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.6862 - val_loss: 0.5543 - val_accuracy: 0.7483\n",
            "Epoch 15/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.5994 - accuracy: 0.6949 - val_loss: 0.5515 - val_accuracy: 0.7497\n",
            "Epoch 16/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6048 - accuracy: 0.6854 - val_loss: 0.5468 - val_accuracy: 0.7497\n",
            "Epoch 17/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6021 - accuracy: 0.6862 - val_loss: 0.5453 - val_accuracy: 0.7521\n",
            "Epoch 18/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.6884 - val_loss: 0.5503 - val_accuracy: 0.7479\n",
            "Epoch 19/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6020 - accuracy: 0.6903 - val_loss: 0.5434 - val_accuracy: 0.7531\n",
            "Epoch 20/20\n",
            "365/365 [==============================] - 1s 2ms/step - loss: 0.6108 - accuracy: 0.6785 - val_loss: 0.5440 - val_accuracy: 0.7503\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f053a8e6b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjHwdB9jMUyY",
        "outputId": "fe25f30b-c402-4fe4-f22d-a366ddbb23ec"
      },
      "source": [
        "model.evaluate(encoded_tweets,encoded_lbls)"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "457/457 [==============================] - 1s 1ms/step - loss: 0.5857 - accuracy: 0.7032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.585696816444397, 0.7032266855239868]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW7xGzeRMe_8",
        "outputId": "b8f53c3b-a535-481d-ef56-b064647faee9"
      },
      "source": [
        "encoded_tweets"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.08465489, 0.13442078,\n",
              "        0.07408246],\n",
              "       [0.        , 0.        , 0.        , ..., 0.21983084, 0.27050295,\n",
              "        0.13064492],\n",
              "       [0.        , 0.        , 0.        , ..., 0.1480139 , 0.90084579,\n",
              "        0.16266425],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.05996073, 0.39457786,\n",
              "        0.89805165],\n",
              "       [0.95861652, 0.17550219, 0.70004531, ..., 0.27752605, 0.08578765,\n",
              "        0.37199819],\n",
              "       [0.71907567, 0.13200423, 0.17587978, ..., 0.21983084, 0.78568192,\n",
              "        0.27057846]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2W43TbKMp20",
        "outputId": "9e9730a7-24b6-4ecb-f16d-cb7fbfb0cdd6"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  txt = encoded_tweets[i]\n",
        "  txt = np.reshape(txt, (1,20))\n",
        "\n",
        "  print(encoded_lbls[i] == int(model.predict(txt)> 0.5))"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "True\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLPvgA51Orv-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}